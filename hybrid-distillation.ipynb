{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151769c1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-15T09:15:15.541656Z",
     "iopub.status.busy": "2026-02-15T09:15:15.541166Z",
     "iopub.status.idle": "2026-02-15T09:15:35.951610Z",
     "shell.execute_reply": "2026-02-15T09:15:35.950674Z"
    },
    "papermill": {
     "duration": 20.417122,
     "end_time": "2026-02-15T09:15:35.953929",
     "exception": false,
     "start_time": "2026-02-15T09:15:15.536807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libreria di sistema\n",
    "import kagglehub\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "# Installa dipendenze base\n",
    "!pip install torch torchvision\n",
    "!pip install pandas numpy matplotlib seaborn\n",
    "!pip install scikit-learn pillow tqdm\n",
    "!pip install jupyter notebook\n",
    "!pip install tensorboard\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2e120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T09:15:35.963388Z",
     "iopub.status.busy": "2026-02-15T09:15:35.962904Z",
     "iopub.status.idle": "2026-02-15T09:15:36.139354Z",
     "shell.execute_reply": "2026-02-15T09:15:36.138526Z"
    },
    "papermill": {
     "duration": 0.182711,
     "end_time": "2026-02-15T09:15:36.140809",
     "exception": false,
     "start_time": "2026-02-15T09:15:35.958098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"rtlmhjbn/ip02-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ff8a9",
   "metadata": {},
   "source": [
    "# Implementazione del Modello, Teacher e Trainer di Distillazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e916d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T09:15:36.150885Z",
     "iopub.status.busy": "2026-02-15T09:15:36.150654Z",
     "iopub.status.idle": "2026-02-15T19:50:41.241721Z",
     "shell.execute_reply": "2026-02-15T19:50:41.240814Z"
    },
    "papermill": {
     "duration": 38105.988311,
     "end_time": "2026-02-15T19:50:42.132808",
     "exception": false,
     "start_time": "2026-02-15T09:15:36.144497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "class IP102Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'convnext_base.fb_in22k_ft_in1k',\n",
    "        num_classes: int = 102,\n",
    "        pretrained: bool = False,\n",
    "        dropout: float = 0.2,\n",
    "        drop_path_rate: float = 0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        \n",
    "        try:\n",
    "            self.backbone = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=pretrained,\n",
    "                num_classes=0,\n",
    "                global_pool='avg',\n",
    "                drop_path_rate=drop_path_rate\n",
    "            )\n",
    "        except:\n",
    "            self.backbone = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=pretrained,\n",
    "                num_classes=0,\n",
    "                global_pool='avg'\n",
    "            )\n",
    "        \n",
    "        if hasattr(self.backbone, \"classifier\") and hasattr(self.backbone.classifier, \"in_features\"):\n",
    "            num_features = self.backbone.classifier.in_features\n",
    "        elif hasattr(self.backbone, \"feature_info\"):\n",
    "            num_features = self.backbone.feature_info[-1][\"num_chs\"]\n",
    "        else:\n",
    "            num_features = getattr(self.backbone, \"num_features\")\n",
    "            \n",
    "        if num_features is None:\n",
    "            with torch.no_grad():\n",
    "                if 'swin' in model_name.lower():\n",
    "                    dummy = torch.randn(1, 3, 224, 224)\n",
    "                elif 'efficientnet' in model_name.lower():\n",
    "                    dummy = torch.randn(1, 3, 384, 384)\n",
    "                else:\n",
    "                    dummy = torch.randn(1, 3, 224, 224)\n",
    "                \n",
    "                self.backbone.eval()\n",
    "                out = self.backbone(dummy)\n",
    "                num_features = out.shape[1]\n",
    "                self.backbone.train()\n",
    "        \n",
    "        # Classifier in base all'architettura\n",
    "        if 'convnext' in model_name.lower():\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(num_features),\n",
    "                nn.Linear(num_features, num_classes)\n",
    "            )\n",
    "        elif 'swin' in model_name.lower():\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(num_features),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(num_features, num_classes)\n",
    "            )\n",
    "        elif 'efficientnet' in model_name.lower():\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "        elif 'mobilenet' in model_name.lower():\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(num_features, num_classes)\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(num_features),\n",
    "                nn.Linear(num_features, num_classes)\n",
    "            )\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        \n",
    "        # Verifica \n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if 'swin' in model_name.lower():\n",
    "                test_input = torch.randn(2, 3, 224, 224)\n",
    "            elif 'efficientnet' in model_name.lower():\n",
    "                test_input = torch.randn(2, 3, 384, 384)\n",
    "            else:\n",
    "                test_input = torch.randn(2, 3, 224, 224)\n",
    "            \n",
    "            test_features = self.backbone.forward_features(test_input)\n",
    "            print(f\"   Raw feature shape from backbone: {test_features.shape}\")\n",
    "            \n",
    "            test_output = self(test_input)\n",
    "            \n",
    "            print(f\"   Output shape:  {test_output.shape}\")\n",
    "            \n",
    "            # Verifica che l'output sia corretto\n",
    "            assert test_output.shape == (2, num_classes), \\\n",
    "                f\"Output shape {test_output.shape} != expected (2, {num_classes})\"\n",
    "        \n",
    "        self.train()\n",
    "        print(f\" {model_name}: {num_features} features - Verified OK!\")\n",
    "    \n",
    "    def forward(self, x, return_features=False):\n",
    "        features = self.backbone.forward_features(x)\n",
    "\n",
    "        # SWIN: NHWC â†’ NCHW \n",
    "        if features.dim() == 4:\n",
    "            # Swin: [B, H, W, C]\n",
    "            if features.shape[-1] > features.shape[1]:\n",
    "                features = features.permute(0, 3, 1, 2).contiguous()\n",
    "            # altrimenti Ã¨ giÃ  [B, C, H, W]\n",
    "\n",
    "        # Global Average Pooling\n",
    "        features_pooled = F.adaptive_avg_pool2d(features, (1, 1))\n",
    "        features_pooled = features_pooled.flatten(1)\n",
    "\n",
    "        logits = self.classifier(features_pooled)\n",
    "\n",
    "        if return_features:\n",
    "            return logits, features\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ENSEMBLE TEACHER (per soft targets)\n",
    "\n",
    "class EnsembleTeacher:\n",
    "    # Ensemble di modelli per generare soft targets\n",
    "    \n",
    "    def __init__(self, models_config, device='cuda'):\n",
    "        self.device = device\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "        \n",
    "        print(\"\\n Caricamento Ensemble Teacher per soft targets\")\n",
    "        \n",
    "        for config in models_config:\n",
    "            print(f\" {config['name']}\")\n",
    "            \n",
    "            model = IP102Classifier(\n",
    "                model_name=config['model_name'],\n",
    "                num_classes=102,\n",
    "                pretrained=False\n",
    "            )\n",
    "            \n",
    "            checkpoint = torch.load(config['checkpoint_path'], map_location=device, weights_only=False)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "            \n",
    "            self.models.append(model)\n",
    "            self.weights.append(config.get('weight', 1.0))\n",
    "        \n",
    "        # Normalizza pesi\n",
    "        total_weight = sum(self.weights)\n",
    "        self.weights = [w / total_weight for w in self.weights]\n",
    "        \n",
    "        print(f\"Ensemble pronto: {len(self.models)} modelli\")\n",
    "        print(f\"Pesi: {[f'{w:.3f}' for w in self.weights]}\")\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_logits(self, images):\n",
    "        logits_ens = None\n",
    "        for w, model in zip(self.weights, self.models):\n",
    "            logits = model(images)\n",
    "            logits_ens = logits * w if logits_ens is None else logits_ens + w * logits\n",
    "        return logits_ens\n",
    "\n",
    "\n",
    "# FEATURE TEACHER (per feature distillation)\n",
    "class FeatureTeacher:\n",
    "    # Singolo modello per estrarre feature intermedie \n",
    "    \n",
    "    def __init__(self, model_config, device='cuda'):\n",
    "        self.device = device\n",
    "        \n",
    "        print(f\"\\n Caricamento Feature Teacher: {model_config['name']}\")\n",
    "        \n",
    "        self.model = IP102Classifier(\n",
    "            model_name=model_config['model_name'],\n",
    "            num_classes=102,\n",
    "            pretrained=False\n",
    "        )\n",
    "        \n",
    "        checkpoint = torch.load(model_config['checkpoint_path'], map_location=device, weights_only=False)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.num_features = self.model.num_features\n",
    "        \n",
    "        print(f\"Feature teacher pronto\")\n",
    "        print(f\"Features: {self.num_features}\")\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_features(self, images):\n",
    "        # Estrae feature intermedie dal teacher.\n",
    "        # Restituisce sempre feature in formato [B, C, H, W] per la distillation.\n",
    "\n",
    "        features = self.model.backbone.forward_features(images)\n",
    "        \n",
    "        # Converti sempre a formato 4D [B, C, H, W]\n",
    "        if len(features.shape) == 4:  \n",
    "            return features\n",
    "        elif len(features.shape) == 3:\n",
    "            B, N, C = features.shape\n",
    "            H = W = int(N ** 0.5)\n",
    "            if H * W == N:\n",
    "                # Reshape a 2D feature map\n",
    "                features = features.transpose(1, 2).reshape(B, C, H, W)\n",
    "            else:\n",
    "                # Fallback: tratta come 1x1 feature map\n",
    "                features = features.mean(dim=1).unsqueeze(-1).unsqueeze(-1)\n",
    "        else:  # [B, C] \n",
    "            features = features.unsqueeze(-1).unsqueeze(-1)  # [B, C, 1, 1]\n",
    "        \n",
    "        return features\n",
    "\n",
    "# IMPROVED GROUP CONVOLUTION MAPPING LAYER\n",
    "\n",
    "\n",
    "class GroupConvMappingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        student_channels,\n",
    "        teacher_channels,\n",
    "        inner_channels=None,\n",
    "        conv1_groups=16,\n",
    "        conv2_groups=4,\n",
    "        kernel_size=3,\n",
    "        use_residual=True,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if inner_channels is None:\n",
    "            inner_channels = student_channels // 2\n",
    "            inner_channels = max(256, min(768, inner_channels))\n",
    "        \n",
    "        self.student_channels = student_channels\n",
    "        self.teacher_channels = teacher_channels\n",
    "        self.use_residual = use_residual and (student_channels == teacher_channels)\n",
    "        \n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            student_channels,\n",
    "            inner_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            groups=conv1_groups,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(inner_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            inner_channels,\n",
    "            teacher_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            groups=conv2_groups,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(teacher_channels)\n",
    "        \n",
    "        if self.use_residual:\n",
    "            self.skip = nn.Identity()\n",
    "        elif student_channels != teacher_channels:\n",
    "            self.skip = nn.Conv2d(student_channels, teacher_channels, 1, bias=False)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "        self.num_params = sum(p.numel() for p in self.parameters())\n",
    "        \n",
    "        print(f\" Improved Mapping Layer:\")\n",
    "        print(f\" {student_channels} â†’ {inner_channels} â†’ {teacher_channels}\")\n",
    "        print(f\" Compression ratio: {inner_channels/student_channels:.2%}\")\n",
    "        print(f\" Groups: {conv1_groups}, {conv2_groups}\")\n",
    "        print(f\" Residual: {self.use_residual}\")\n",
    "        print(f\" Dropout: {dropout}\")\n",
    "        print(f\" Params: {self.num_params:,}\")\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.use_residual:\n",
    "            out = out + identity\n",
    "        elif hasattr(self, 'skip') and not isinstance(self.skip, nn.Identity):\n",
    "            out = out + self.skip(identity)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# DEBUG\n",
    "def tensor_stats(name, x):\n",
    "    return {\n",
    "        'name': name,\n",
    "        'shape': list(x.shape),\n",
    "        'min': x.min().item(),\n",
    "        'max': x.max().item(),\n",
    "        'mean': x.mean().item(),\n",
    "        'std': x.std().item(),\n",
    "        'l2_norm': x.norm(p=2).item()\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# HYBRID KNOWLEDGE DISTILLATION TRAINER\n",
    "\n",
    "\n",
    "class HybridDistillationTrainer:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        student_model,\n",
    "        ensemble_teacher,\n",
    "        feature_teacher,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        device='cuda',\n",
    "        save_dir='./hybrid_distillation',\n",
    "        temperature=10.0,\n",
    "        gamma_feature_start=0.1,\n",
    "        gamma_feature_end=0.5,\n",
    "        gamma_soft=0.6,\n",
    "        feature_loss_type='cosine',\n",
    "        use_mixup=True,\n",
    "        mixup_alpha=0.2,\n",
    "        use_ema=True,\n",
    "        ema_decay=0.999,\n",
    "        inner_channels=None,\n",
    "        conv1_groups=8,\n",
    "        conv2_groups=4,\n",
    "        kernel_size=3,\n",
    "        mapping_dropout=0.1,\n",
    "        learning_rate=1e-3,\n",
    "        weight_decay=0.01,\n",
    "        num_epochs=50,\n",
    "        warmup_epochs=10,\n",
    "        use_amp=True,\n",
    "        gradient_clip=1.0\n",
    "    ):\n",
    "        self.student = student_model.to(device)\n",
    "        self.ensemble_teacher = ensemble_teacher\n",
    "        self.feature_teacher = feature_teacher\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        self.gamma_feature_start = gamma_feature_start\n",
    "        self.gamma_feature_end = gamma_feature_end\n",
    "        self.gamma_soft = gamma_soft\n",
    "        self.current_gamma_feature = gamma_feature_start\n",
    "        self.feature_loss_type = feature_loss_type\n",
    "        \n",
    "        self.use_mixup = use_mixup\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "    \n",
    "        self.use_ema = use_ema\n",
    "        if use_ema:\n",
    "            self.ema_model = self._create_ema_model()\n",
    "            self.ema_decay = ema_decay\n",
    "        \n",
    "        student_channels = self.student.num_features\n",
    "        teacher_channels = self.feature_teacher.num_features\n",
    "        \n",
    "        print(f\"\\n Creazione improved mapping layer\")\n",
    "        self.mapping_layer = GroupConvMappingLayer(\n",
    "            student_channels=student_channels,\n",
    "            teacher_channels=teacher_channels,\n",
    "            inner_channels=inner_channels,\n",
    "            conv1_groups=conv1_groups,\n",
    "            conv2_groups=conv2_groups,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=mapping_dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        self.optimizer = optim.AdamW(\n",
    "            list(self.student.parameters()) + list(self.mapping_layer.parameters()),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        self.warmup_scheduler = optim.lr_scheduler.LinearLR(\n",
    "            self.optimizer,\n",
    "            start_factor=0.01,\n",
    "            total_iters=self.warmup_epochs\n",
    "        )\n",
    "        \n",
    "        self.main_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer,\n",
    "            T_max=num_epochs - warmup_epochs,\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        self.use_amp = use_amp\n",
    "        self.scaler = GradScaler(enabled=use_amp)\n",
    "        self.gradient_clip = gradient_clip\n",
    "        \n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [], 'train_loss_feature': [], \n",
    "            'train_loss_soft': [], 'train_loss_hard': [],\n",
    "            'val_loss': [], 'train_acc': [], 'val_acc': [], \n",
    "            'val_balanced_acc': [], 'val_f1': [],\n",
    "            'gamma_feature': [],\n",
    "            'test_acc': None, 'test_balanced_acc': None, 'test_f1': None\n",
    "        }\n",
    "        \n",
    "        self.best_val_balanced_acc = 0.0\n",
    "        \n",
    "        print(f\"\\n Improved Hybrid Distillation Setup:\")\n",
    "        print(f\"Temperature: {temperature}\")\n",
    "        print(f\"Î³_feature: {gamma_feature_start} â†’ {gamma_feature_end} (adaptive)\")\n",
    "        print(f\"Î³_soft:    {gamma_soft}\")\n",
    "        print(f\"Feature loss: {feature_loss_type}\")\n",
    "        print(f\"Mixup: {use_mixup} (Î±={mixup_alpha})\")\n",
    "        print(f\"EMA: {use_ema} (decay={ema_decay})\")\n",
    "        print(f\"Gradient clip: {gradient_clip}\")\n",
    "        print(f\"LR: {learning_rate}, Epochs: {num_epochs}, Warmup: {warmup_epochs}\")\n",
    "        print(f\"Student params: {sum(p.numel() for p in student_model.parameters()) / 1e6:.2f}M\")\n",
    "        print(f\"Mapping params: {self.mapping_layer.num_params / 1e6:.2f}M\")\n",
    "    \n",
    "    def _create_ema_model(self):\n",
    "        ema_student = IP102Classifier(\n",
    "            model_name=self.student.model_name,\n",
    "            num_classes=102,\n",
    "            pretrained=False\n",
    "        ).to(self.device)\n",
    "        ema_student.load_state_dict(self.student.state_dict())\n",
    "        ema_student.eval()\n",
    "        return ema_student\n",
    "    \n",
    "    def _update_ema(self):\n",
    "        if not self.use_ema:\n",
    "            return\n",
    "        with torch.no_grad():\n",
    "            for ema_param, param in zip(self.ema_model.parameters(), \n",
    "                                        self.student.parameters()):\n",
    "                ema_param.data.mul_(self.ema_decay).add_(\n",
    "                    param.data, alpha=1 - self.ema_decay\n",
    "                )\n",
    "    \n",
    "    def _mixup_data(self, x, y):\n",
    "        if not self.use_mixup:\n",
    "            return x, y, None, None\n",
    "        \n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "        batch_size = x.size(0)\n",
    "        index = torch.randperm(batch_size, device=x.device)\n",
    "        \n",
    "        mixed_x = lam * x + (1 - lam) * x[index]\n",
    "        y_a, y_b = y, y[index]\n",
    "        \n",
    "        return mixed_x, y_a, y_b, lam\n",
    "    \n",
    "    def _update_gamma_feature(self, epoch):\n",
    "        if epoch <= self.warmup_epochs:\n",
    "            progress = epoch / self.warmup_epochs\n",
    "            self.current_gamma_feature = (\n",
    "                self.gamma_feature_start + \n",
    "                (self.gamma_feature_end - self.gamma_feature_start) * progress\n",
    "            )\n",
    "        else:\n",
    "            self.current_gamma_feature = self.gamma_feature_end\n",
    "        return self.current_gamma_feature\n",
    "    \n",
    "    def compute_distillation_loss(self, images, labels, y_a=None, y_b=None, lam=None):\n",
    "        student_logits, student_features = self.student(images, return_features=True)\n",
    "        \n",
    "        # 1. FEATURE DISTILLATION\n",
    "        with torch.no_grad():\n",
    "            teacher_features = self.feature_teacher.get_features(images)\n",
    "        \n",
    "        if student_features.shape[2:] != teacher_features.shape[2:]:\n",
    "            student_features = F.interpolate(\n",
    "                student_features,\n",
    "                size=teacher_features.shape[2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        \n",
    "        mapped_student_features = self.mapping_layer(student_features)\n",
    "        \n",
    "        if self.feature_loss_type == 'cosine':\n",
    "            teacher_norm = F.normalize(teacher_features, p=2, dim=1)\n",
    "            student_norm = F.normalize(mapped_student_features, p=2, dim=1)\n",
    "            loss_feature = 1 - F.cosine_similarity(\n",
    "                student_norm.flatten(1), \n",
    "                teacher_norm.flatten(1), \n",
    "                dim=1\n",
    "            ).mean()\n",
    "        else:\n",
    "            B, C, H, W = teacher_features.shape\n",
    "            loss_feature = F.mse_loss(\n",
    "                mapped_student_features, \n",
    "                teacher_features, \n",
    "                reduction='sum'\n",
    "            ) / (H * W * B)\n",
    "        \n",
    "        # 2. SOFT TARGETS DISTILLATION\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.ensemble_teacher.get_logits(images)\n",
    "        \n",
    "        teacher_probs = F.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        student_log_probs = F.log_softmax(student_logits / self.temperature, dim=1)\n",
    "        \n",
    "        loss_soft = F.kl_div(\n",
    "            student_log_probs,\n",
    "            teacher_probs,\n",
    "            reduction='batchmean'\n",
    "        ) * (self.temperature ** 2)\n",
    "        \n",
    "        # 3. HARD TARGETS\n",
    "        if lam is not None:\n",
    "            loss_hard = (\n",
    "                lam * F.cross_entropy(student_logits, y_a) +\n",
    "                (1 - lam) * F.cross_entropy(student_logits, y_b)\n",
    "            )\n",
    "        else:\n",
    "            loss_hard = F.cross_entropy(student_logits, labels)\n",
    "        \n",
    "        gamma_hard = 1.0 - (self.current_gamma_feature + self.gamma_soft) / 2.0\n",
    "        \n",
    "        total_loss = (\n",
    "            self.current_gamma_feature * loss_feature +\n",
    "            self.gamma_soft * loss_soft +\n",
    "            gamma_hard * loss_hard\n",
    "        )\n",
    "        \n",
    "        return (total_loss, loss_feature.item(), loss_soft.item(), \n",
    "                loss_hard.item(), student_features, mapped_student_features, \n",
    "                teacher_features)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        self.student.train()\n",
    "        self.mapping_layer.train()\n",
    "        \n",
    "        gamma_feat = self._update_gamma_feature(epoch)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_loss_feature = 0.0\n",
    "        running_loss_soft = 0.0\n",
    "        running_loss_hard = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}/{self.num_epochs}')\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            mixed_images, y_a, y_b, lam = self._mixup_data(images, labels)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            with autocast(enabled=self.use_amp):\n",
    "                if lam is not None:\n",
    "                    loss, loss_feat, loss_soft, loss_hard, sf, msf, tf = \\\n",
    "                        self.compute_distillation_loss(mixed_images, labels, y_a, y_b, lam)\n",
    "                else:\n",
    "                    loss, loss_feat, loss_soft, loss_hard, sf, msf, tf = \\\n",
    "                        self.compute_distillation_loss(images, labels)\n",
    "            \n",
    "            # DEBUG: primo batch\n",
    "            if epoch == 1 and batch_idx == 0:\n",
    "                with torch.no_grad():\n",
    "                    stats = [\n",
    "                        tensor_stats(\"Student features\", sf),\n",
    "                        tensor_stats(\"Mapped student features\", msf),\n",
    "                        tensor_stats(\"Teacher features\", tf)\n",
    "                    ]\n",
    "                    print(\" FEATURE SCALE DEBUG (First Batch)\")\n",
    "                    for s in stats:\n",
    "                        print(\n",
    "                            f\"{s['name']:30s} | \"\n",
    "                            f\"shape={s['shape']} | \"\n",
    "                            f\"min={s['min']:8.3f} max={s['max']:8.3f} | \"\n",
    "                            f\"mean={s['mean']:8.3f} std={s['std']:8.3f} | \"\n",
    "                            f\"L2={s['l2_norm']:10.2f}\"\n",
    "                        )\n",
    "            \n",
    "            if self.use_amp:\n",
    "                self.scaler.scale(loss).backward()\n",
    "                if self.gradient_clip > 0:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        list(self.student.parameters()) + \n",
    "                        list(self.mapping_layer.parameters()),\n",
    "                        self.gradient_clip\n",
    "                    )\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                if self.gradient_clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        list(self.student.parameters()) + \n",
    "                        list(self.mapping_layer.parameters()),\n",
    "                        self.gradient_clip\n",
    "                    )\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            self._update_ema()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_loss_feature += loss_feat * images.size(0)\n",
    "            running_loss_soft += loss_soft * images.size(0)\n",
    "            running_loss_hard += loss_hard * images.size(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                student_logits = self.student(images)\n",
    "                preds = torch.argmax(student_logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'Î³_feat': f'{gamma_feat:.3f}',\n",
    "                'acc': f'{correct/total:.4f}'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "        epoch_loss_feature = running_loss_feature / len(self.train_loader.dataset)\n",
    "        epoch_loss_soft = running_loss_soft / len(self.train_loader.dataset)\n",
    "        epoch_loss_hard = running_loss_hard / len(self.train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "        if epoch <= self.warmup_epochs:\n",
    "            self.warmup_scheduler.step()\n",
    "        else:\n",
    "            self.main_scheduler.step()\n",
    "        \n",
    "        return epoch_loss, epoch_loss_feature, epoch_loss_soft, epoch_loss_hard, epoch_acc\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch, use_ema=False):\n",
    "        model = self.ema_model if (use_ema and self.use_ema) else self.student\n",
    "        model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for images, labels in tqdm(self.val_loader, \n",
    "                                   desc=f'Validation {epoch} {\"(EMA)\" if use_ema else \"\"}'):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            logits = model(images)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = running_loss / len(self.val_loader.dataset)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        val_balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        return val_loss, val_acc, val_balanced_acc, val_f1\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def test(self, use_ema=False):\n",
    "        print(f\"TEST SET EVALUATION {'(EMA)' if use_ema else ''}\")\n",
    "        \n",
    "        model = self.ema_model if (use_ema and self.use_ema) else self.student\n",
    "        model.eval()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(self.test_loader, desc='Testing'):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            logits = model(images)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_loss = running_loss / len(self.test_loader.dataset)\n",
    "        test_acc = accuracy_score(all_labels, all_preds)\n",
    "        test_balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        print(f\"\\nTest Loss:        {test_loss:.4f}\")\n",
    "        print(f\"Test Accuracy:    {test_acc:.4f}\")\n",
    "        print(f\"Balanced Acc:     {test_balanced_acc:.4f}\")\n",
    "        print(f\"F1 Macro:         {test_f1:.4f}\")\n",
    "        \n",
    "        return test_loss, test_acc, test_balanced_acc, test_f1\n",
    "    \n",
    "    def train(self):\n",
    "        print(\" STARTING HYBRID DISTILLATION TRAINING\")\n",
    "\n",
    "        \n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            train_loss, loss_feat, loss_soft, loss_hard, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc, val_balanced_acc, val_f1 = self.validate(epoch, use_ema=False)\n",
    "            \n",
    "            if self.use_ema:\n",
    "                ema_val_loss, ema_val_acc, ema_val_balanced_acc, ema_val_f1 = \\\n",
    "                    self.validate(epoch, use_ema=True)\n",
    "            \n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_loss_feature'].append(loss_feat)\n",
    "            self.history['train_loss_soft'].append(loss_soft)\n",
    "            self.history['train_loss_hard'].append(loss_hard)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_balanced_acc'].append(val_balanced_acc)\n",
    "            self.history['val_f1'].append(val_f1)\n",
    "            self.history['gamma_feature'].append(self.current_gamma_feature)\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch}/{self.num_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f} \"\n",
    "                  f\"(feat:{loss_feat:.4f} soft:{loss_soft:.4f} hard:{loss_hard:.4f})\")\n",
    "            print(f\"Train Acc:  {train_acc:.4f}\")\n",
    "            print(f\"Val Loss:   {val_loss:.4f}\")\n",
    "            print(f\"Val Acc:    {val_acc:.4f} | Balanced: {val_balanced_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "            \n",
    "            if self.use_ema:\n",
    "                print(f\"EMA Val:    {ema_val_acc:.4f} | Balanced: {ema_val_balanced_acc:.4f} | F1: {ema_val_f1:.4f}\")\n",
    "            \n",
    "            print(f\"Î³_feature:  {self.current_gamma_feature:.3f}\")\n",
    "            print(f\"LR:         {current_lr:.6e}\")\n",
    "            \n",
    "            best_metric = ema_val_balanced_acc if self.use_ema else val_balanced_acc\n",
    "            is_best = best_metric > self.best_val_balanced_acc\n",
    "            \n",
    "            if is_best:\n",
    "                self.best_val_balanced_acc = best_metric\n",
    "                self.save_checkpoint(epoch, is_best=True)\n",
    "                print(f\" Best model! Balanced Acc: {best_metric:.4f}\")\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                self.save_checkpoint(epoch, is_best=False)\n",
    "        \n",
    "        test_loss, test_acc, test_balanced_acc, test_f1 = self.test(use_ema=self.use_ema)\n",
    "        self.history['test_acc'] = test_acc\n",
    "        self.history['test_balanced_acc'] = test_balanced_acc\n",
    "        self.history['test_f1'] = test_f1\n",
    "        \n",
    "        self.save_history()\n",
    "        self.plot_training_curves()\n",
    "        \n",
    "        print(\"\\n TRAINING COMPLETED\")\n",
    "        print(f\"Best Val Balanced Acc: {self.best_val_balanced_acc:.4f}\")\n",
    "        print(f\"Test Balanced Acc:     {test_balanced_acc:.4f}\")\n",
    "    \n",
    "    def save_checkpoint(self, epoch, is_best=False):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'student_state_dict': self.student.state_dict(),\n",
    "            'mapping_layer_state_dict': self.mapping_layer.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'best_val_balanced_acc': self.best_val_balanced_acc,\n",
    "            'history': self.history\n",
    "        }\n",
    "        \n",
    "        if self.use_ema:\n",
    "            checkpoint['ema_state_dict'] = self.ema_model.state_dict()\n",
    "        \n",
    "        if is_best:\n",
    "            path = self.save_dir / 'best_model.pth'\n",
    "            torch.save(checkpoint, path)\n",
    "            print(f\" Best model saved: {path}\")\n",
    "        else:\n",
    "            path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'\n",
    "            torch.save(checkpoint, path)\n",
    "    \n",
    "    def save_history(self):\n",
    "        with open(self.save_dir / 'history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "    \n",
    "    def plot_training_curves(self):\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        epochs = range(1, len(self.history['train_loss']) + 1)\n",
    "        \n",
    "        axes[0, 0].plot(epochs, self.history['train_loss_feature'], label='Feature Loss')\n",
    "        axes[0, 0].plot(epochs, self.history['train_loss_soft'], label='Soft Loss')\n",
    "        axes[0, 0].plot(epochs, self.history['train_loss_hard'], label='Hard Loss')\n",
    "        axes[0, 0].set_title('Loss Components')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(alpha=0.3)\n",
    "        \n",
    "        axes[0, 1].plot(epochs, self.history['train_loss'], label='Train')\n",
    "        axes[0, 1].plot(epochs, self.history['val_loss'], label='Val')\n",
    "        axes[0, 1].set_title('Total Loss')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(alpha=0.3)\n",
    "        \n",
    "        axes[0, 2].plot(epochs, self.history['train_acc'], label='Train', linestyle='--')\n",
    "        axes[0, 2].plot(epochs, self.history['val_acc'], label='Val')\n",
    "        axes[0, 2].set_title('Accuracy')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(alpha=0.3)\n",
    "        \n",
    "        axes[1, 0].plot(epochs, self.history['val_balanced_acc'], label='Balanced Acc')\n",
    "        axes[1, 0].plot(epochs, self.history['val_f1'], label='F1')\n",
    "        axes[1, 0].set_title('Validation Metrics')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(alpha=0.3)\n",
    "        \n",
    "        axes[1, 1].plot(epochs, self.history['gamma_feature'], color='purple')\n",
    "        axes[1, 1].set_title('Feature Distillation Weight (Î³_feature)')\n",
    "        axes[1, 1].set_ylabel('Î³_feature')\n",
    "        axes[1, 1].grid(alpha=0.3)\n",
    "        \n",
    "        gap = np.array(self.history['train_acc']) - np.array(self.history['val_acc'])\n",
    "        axes[1, 2].plot(epochs, gap, color='red')\n",
    "        axes[1, 2].set_title('Train-Val Gap (Overfitting Monitor)')\n",
    "        axes[1, 2].set_ylabel('Train Acc - Val Acc')\n",
    "        axes[1, 2].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "        axes[1, 2].grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.save_dir / 'training_curves.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Training curves saved\")\n",
    "\n",
    "\n",
    "\n",
    "# CONFUSION MATRIX E VISUALIZZAZIONE\n",
    "\n",
    "def plot_confusion_matrix(model, test_loader, device, save_path, class_names=None):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\" GENERATING CONFUSION MATRIX\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Computing predictions'):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            logits = model(images)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "    \n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names if class_names else 'auto',\n",
    "                yticklabels=class_names if class_names else 'auto',\n",
    "                ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=False, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names if class_names else 'auto',\n",
    "                yticklabels=class_names if class_names else 'auto',\n",
    "                ax=axes[1], cbar_kws={'label': 'Proportion'}, vmin=0, vmax=1)\n",
    "    axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\" Confusion matrix saved: {save_path}\")\n",
    "    \n",
    "    per_class_acc = cm_normalized.diagonal()\n",
    "    print(f\"\\nPer-class accuracy statistics:\")\n",
    "    print(f\"  Mean:   {per_class_acc.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(per_class_acc):.4f}\")\n",
    "    print(f\"  Min:    {per_class_acc.min():.4f}\")\n",
    "    print(f\"  Max:    {per_class_acc.max():.4f}\")\n",
    "    \n",
    "    return cm, cm_normalized\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_20(model, test_loader, device, save_path, class_names=None):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸ“Š GENERATING CONFUSION MATRIX\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Computing predictions'):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            logits = model(images)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Filtra solo le prime 20 classi\n",
    "    mask_20 = all_labels < 20\n",
    "    all_preds_20 = all_preds[mask_20]\n",
    "    all_labels_20 = all_labels[mask_20]\n",
    "\n",
    "    print(f\" Filtering to first 20 classes:\")\n",
    "    print(f\" Total samples: {len(all_labels)} â†’ {len(all_labels_20)} (first 20 classes)\")\n",
    "    \n",
    "    cm = confusion_matrix(all_labels_20, all_preds_20, labels=np.arange(20))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Nomi delle classi per le prime 20\n",
    "    if class_names is not None:\n",
    "        class_names_20 = class_names[:20]\n",
    "    else:\n",
    "        class_names_20 = [f'Class {i}' for i in range(20)]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names_20,\n",
    "                yticklabels=class_names_20,\n",
    "                ax=axes[0], cbar_kws={'label': 'Count'},\n",
    "                annot_kws={'fontsize': 8})\n",
    "    axes[0].set_title('Confusion Matrix (Counts) - First 20 Classes', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    axes[0].tick_params(axis='both', labelsize=9)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=False, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names_20,\n",
    "                yticklabels=class_names_20,\n",
    "                ax=axes[1], cbar_kws={'label': 'Proportion'}, vmin=0, vmax=1,\n",
    "                annot_kws={'fontsize': 8})\n",
    "    axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    axes[1].tick_params(axis='both', labelsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\" Confusion matrix (20 classes) saved: {save_path}\")\n",
    "    \n",
    "    per_class_acc_20 = cm_normalized.diagonal()\n",
    "    print(f\"\\nPer-class accuracy statistics (first 20 classes):\")\n",
    "    print(f\"  Mean:   {per_class_acc_20.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(per_class_acc_20):.4f}\")\n",
    "    print(f\"  Min:    {per_class_acc_20.min():.4f}\")\n",
    "    print(f\"  Max:    {per_class_acc_20.max():.4f}\")\n",
    "\n",
    "    worst_5_idx = np.argsort(per_class_acc_20)[:5]\n",
    "    print(f\"\\n 5 Worst performing classes:\")\n",
    "    for idx in worst_5_idx:\n",
    "        class_name = class_names_20[idx] if class_names_20 else f\"Class {idx}\"\n",
    "        print(f\"   {class_name}: {per_class_acc_20[idx]:.4f}\")\n",
    "    \n",
    "    return cm, cm_normalized\n",
    "\n",
    "# CONFRONTO MODELLI CON ISTOGRAMMI PER CLASSE\n",
    "\n",
    "def compare_models_per_class_histogram(\n",
    "    ensemble_teacher,\n",
    "    distilled_model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    save_dir,\n",
    "    class_names=None,\n",
    "    num_classes_to_show=11\n",
    "):\n",
    "\n",
    "    print(\" PER-CLASS MODEL COMPARISON\")\n",
    "    \n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def compute_per_class_accuracy(model, is_ensemble=False):\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc='Evaluating'):\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                if is_ensemble:\n",
    "                    logits = model.get_logits(images)\n",
    "                else:\n",
    "                    logits = model(images)\n",
    "                \n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        per_class_acc = []\n",
    "        per_class_support = []\n",
    "        \n",
    "        for class_id in range(102):\n",
    "            mask = all_labels == class_id\n",
    "            support = mask.sum()\n",
    "            per_class_support.append(support)\n",
    "            \n",
    "            if support > 0:\n",
    "                class_acc = (all_preds[mask] == class_id).mean()\n",
    "                per_class_acc.append(class_acc)\n",
    "            else:\n",
    "                per_class_acc.append(0.0)\n",
    "        \n",
    "        return np.array(per_class_acc), np.array(per_class_support)\n",
    "    \n",
    "    print(\"\\n Evaluating Teacher (Ensemble)\")\n",
    "    teacher_acc, teacher_support = compute_per_class_accuracy(ensemble_teacher, is_ensemble=True)\n",
    "    \n",
    "    print(\" Evaluating Distilled Student\")\n",
    "    distilled_acc, distilled_support = compute_per_class_accuracy(distilled_model, is_ensemble=False)\n",
    "    \n",
    "\n",
    "    print(\" GLOBAL METRICS\")\n",
    "    print(f\"\\n{'Model':<25} {'Mean Acc':<12} {'Median Acc':<12} {'Min Acc':<12} {'Max Acc':<12}\")\n",
    "    print(f\"{'Teacher (Ensemble)':<25} {teacher_acc.mean():<12.4f} {np.median(teacher_acc):<12.4f} {teacher_acc.min():<12.4f} {teacher_acc.max():<12.4f}\")\n",
    "    print(f\"{'KD (Distilled)':<25} {distilled_acc.mean():<12.4f} {np.median(distilled_acc):<12.4f} {distilled_acc.min():<12.4f} {distilled_acc.max():<12.4f}\")\n",
    "\n",
    "    valid_classes = np.arange(len(distilled_acc))  # tutte le classi\n",
    "    sorted_indices = np.argsort(distilled_acc[valid_classes])\n",
    "    step = max(1, len(sorted_indices) // (num_classes_to_show - 1))\n",
    "    selected_indices = sorted_indices[::step][:num_classes_to_show]\n",
    "    selected_indices = selected_indices[np.argsort(distilled_acc[valid_classes[selected_indices]])]\n",
    "    classes_to_show = valid_classes[selected_indices]\n",
    "    \n",
    "    if class_names is None:\n",
    "        display_names = [f\"Class {i}\" for i in classes_to_show]\n",
    "    else:\n",
    "        display_names = [class_names[i] if i < len(class_names) else f\"Class {i}\" \n",
    "                        for i in classes_to_show]\n",
    "    \n",
    "    print(f\"\\n Selected {num_classes_to_show} classes (sorted by Non-distilled accuracy):\")\n",
    "    print(f\"Class IDs: {classes_to_show.tolist()}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    x = np.arange(len(classes_to_show))\n",
    "    width = 0.35\n",
    "    \n",
    "    teacher_values = teacher_acc[classes_to_show]\n",
    "    distilled_values = distilled_acc[classes_to_show]\n",
    "    \n",
    "    color_teacher = '#1f77b4'\n",
    "    color_distilled = '#2ca02c'\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, teacher_values, width, \n",
    "                   label='Teacher', color=color_teacher, edgecolor='black', linewidth=0.5)\n",
    "    bars2 = ax.bar(x + width/2, distilled_values, width, \n",
    "                   label='KD (Improved)', color=color_distilled, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Class', fontsize=14)\n",
    "    ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax.set_title('Model Comparison', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(display_names, rotation=45, ha='right', fontsize=11)\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.legend(fontsize=11, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'per_class_comparison.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    print(f\"Plot saved: {save_dir / 'per_class_comparison.png'}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    def get_global_metrics(model, is_ensemble=False):\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                if is_ensemble:\n",
    "                    logits = model.get_logits(images)\n",
    "                else:\n",
    "                    logits = model(images)\n",
    "                \n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        return [acc, bal_acc, f1]\n",
    "    \n",
    "    print(\"\\n Computing global metrics\")\n",
    "    teacher_metrics = get_global_metrics(ensemble_teacher, is_ensemble=True)\n",
    "    distilled_metrics = get_global_metrics(distilled_model, is_ensemble=False)\n",
    "    \n",
    "    metrics_names = ['Accuracy', 'Balanced Accuracy', 'F1 Macro']\n",
    "    x_metrics = np.arange(len(metrics_names))\n",
    "    \n",
    "    bars1 = ax.bar(x_metrics - width/2, teacher_metrics, width, \n",
    "                   label='Teacher', color=color_teacher, edgecolor='black', linewidth=1.5)\n",
    "    bars2 = ax.bar(x_metrics + width/2, distilled_metrics, width, \n",
    "                   label='KD (Improved)', color=color_distilled, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    def add_values(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    add_values(bars1)\n",
    "    add_values(bars2)\n",
    "    \n",
    "    ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Global Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x_metrics)\n",
    "    ax.set_xticklabels(metrics_names, fontsize=11)\n",
    "    ax.legend(fontsize=10, loc='lower right')\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'global_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" Global metrics plot saved\")\n",
    "    \n",
    "    results_dict = {\n",
    "        'global_metrics': {\n",
    "            'teacher': {\n",
    "                'accuracy': float(teacher_metrics[0]),\n",
    "                'balanced_accuracy': float(teacher_metrics[1]),\n",
    "                'f1_macro': float(teacher_metrics[2]),\n",
    "            },\n",
    "            'distilled': {\n",
    "                'accuracy': float(distilled_metrics[0]),\n",
    "                'balanced_accuracy': float(distilled_metrics[1]),\n",
    "                'f1_macro': float(distilled_metrics[2]),\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(save_dir / 'detailed_comparison.json', 'w') as f:\n",
    "        json.dump(results_dict, f, indent=2)\n",
    "    \n",
    "    print(f\" Detailed results saved\")\n",
    "    print(\" PER-CLASS COMPARISON COMPLETED\")\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "# MAIN\n",
    "\n",
    "def main():\n",
    "    CONFIG = {\n",
    "        'train_dir': '/kaggle/input/ip02-dataset/classification/train',\n",
    "        'val_dir': '/kaggle/input/ip02-dataset/classification/val',\n",
    "        'test_dir': '/kaggle/input/ip02-dataset/classification/test',\n",
    "        'save_dir': '/kaggle/working/hybrid_distillation_improved',\n",
    "        \n",
    "        'batch_size': 128,\n",
    "        'img_size': 224,\n",
    "        'num_workers': 4,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        \n",
    "        'num_epochs': 30,\n",
    "        'warmup_epochs': 10,\n",
    "        'learning_rate': 5e-4,\n",
    "        'weight_decay': 0.05,\n",
    "        \n",
    "        'temperature': 10.0,\n",
    "        'gamma_feature_start': 0.1,\n",
    "        'gamma_feature_end': 0.5,\n",
    "        'gamma_soft': 0.6,\n",
    "        'feature_loss_type': 'cosine',\n",
    "        'use_mixup': True,\n",
    "        'mixup_alpha': 0.2,\n",
    "        'use_ema': False,\n",
    "        'ema_decay': 0.999,\n",
    "        'gradient_clip': 1.0,\n",
    "        \n",
    "        'inner_channels': None,\n",
    "        'conv1_groups': 8,\n",
    "        'conv2_groups': 4,\n",
    "        'kernel_size': 3,\n",
    "        'mapping_dropout': 0.1,\n",
    "    }\n",
    "    \n",
    "    ensemble_config = [\n",
    "        {\n",
    "            'name': 'ConvNext-Base',\n",
    "            'model_name': 'convnext_base.fb_in22k_ft_in1k',\n",
    "            'checkpoint_path': '/kaggle/input/convnext-15-epoch/checkpoints/best_model.pth',\n",
    "            'weight': 1.2\n",
    "        },\n",
    "        {\n",
    "            'name': 'Swin-Base',\n",
    "            'model_name': 'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
    "            'checkpoint_path': '/kaggle/input/swin-base-25-epochs/best_model.pth',\n",
    "            'weight': 1.3\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    feature_teacher_config = {\n",
    "        'name': 'ConvNext-Base',\n",
    "        'model_name': 'convnext_base.fb_in22k_ft_in1k',\n",
    "        'checkpoint_path': '/kaggle/input/convnext-15-epoch/checkpoints/best_model.pth',\n",
    "    }\n",
    "    \n",
    "    print(\" HYBRID KNOWLEDGE DISTILLATION\")\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    train_tf = T.Compose([\n",
    "        T.RandomResizedCrop(CONFIG['img_size'], scale=(0.7, 1.0)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomApply([T.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=mean, std=std),\n",
    "        T.RandomErasing(p=0.15)\n",
    "    ])\n",
    "    \n",
    "    val_tf = T.Compose([\n",
    "        T.Resize(int(CONFIG['img_size'] * 1.1)),\n",
    "        T.CenterCrop(CONFIG['img_size']),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "    \n",
    "    train_ds = datasets.ImageFolder(CONFIG['train_dir'], transform=train_tf)\n",
    "\n",
    "    val_ds = datasets.ImageFolder(CONFIG['val_dir'], transform=val_tf)\n",
    "    test_ds = datasets.ImageFolder(CONFIG['test_dir'], transform=val_tf)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], \n",
    "                              shuffle=True, num_workers=CONFIG['num_workers'], \n",
    "                              pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], \n",
    "                            shuffle=False, num_workers=CONFIG['num_workers'], \n",
    "                            pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], \n",
    "                             shuffle=False, num_workers=CONFIG['num_workers'], \n",
    "                             pin_memory=True)\n",
    "    \n",
    "    print(f\"\\n Dataset:\")\n",
    "    print(f\"   Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
    "    \n",
    "    print(f\"\\n Creating Student (MobileNetV3-Large)...\")\n",
    "    student = IP102Classifier(\n",
    "        model_name='mobilenetv3_large_100.miil_in21k_ft_in1k',\n",
    "        num_classes=102,\n",
    "        pretrained=True\n",
    "    )\n",
    "    \n",
    "    ensemble_teacher = EnsembleTeacher(ensemble_config, device=CONFIG['device'])\n",
    "    feature_teacher = FeatureTeacher(feature_teacher_config, device=CONFIG['device'])\n",
    "    \n",
    "    trainer = HybridDistillationTrainer(\n",
    "        student_model=student,\n",
    "        ensemble_teacher=ensemble_teacher,\n",
    "        feature_teacher=feature_teacher,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=CONFIG['device'],\n",
    "        save_dir=CONFIG['save_dir'],\n",
    "        **{k: v for k, v in CONFIG.items() if k not in ['train_dir', 'val_dir', \n",
    "                                                          'test_dir', 'save_dir',\n",
    "                                                          'batch_size', 'img_size',\n",
    "                                                          'num_workers', 'device']}\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    # POST-TRAINING ANALYSIS\n",
    "\n",
    "\n",
    "    print(\" STARTING POST-TRAINING ANALYSIS\")\n",
    "    \n",
    "    print(\"\\n Loading best distilled model for analysis\")\n",
    "    best_checkpoint_path = Path(CONFIG['save_dir']) / 'best_model.pth'\n",
    "    best_checkpoint = torch.load(\n",
    "        best_checkpoint_path,\n",
    "        map_location=CONFIG['device'],\n",
    "        weights_only=False\n",
    "    )\n",
    "    \n",
    "    if trainer.use_ema and 'ema_state_dict' in best_checkpoint:\n",
    "        student.load_state_dict(best_checkpoint['ema_state_dict'])\n",
    "        print(\" Best EMA model loaded for analysis\")\n",
    "    else:\n",
    "        student.load_state_dict(best_checkpoint['student_state_dict'])\n",
    "        print(\" Best student model loaded for analysis\")\n",
    "    \n",
    "    student.eval()\n",
    "    \n",
    "    class_names = None\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        model=student,\n",
    "        test_loader=test_loader,\n",
    "        device=CONFIG['device'],\n",
    "        save_path=Path(CONFIG['save_dir']) / 'confusion_matrix.png',\n",
    "        class_names=class_names\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix_20(\n",
    "        model=student,\n",
    "        test_loader=test_loader,\n",
    "        device=CONFIG['device'],\n",
    "        save_path=Path(CONFIG['save_dir']) / 'confusion_matrix_20classes.png',\n",
    "        class_names=class_names\n",
    "    )\n",
    "    \n",
    "    baseline_checkpoint = '/kaggle/input/mobilenetv3-large-notdistilled/best_model (1).pth'\n",
    "    \n",
    "    comparison_results = compare_models_per_class_histogram(\n",
    "        ensemble_teacher=ensemble_teacher,\n",
    "        distilled_model=student,\n",
    "        test_loader=test_loader,\n",
    "        device=CONFIG['device'],\n",
    "        save_dir=CONFIG['save_dir'],\n",
    "        class_names=class_names,\n",
    "        num_classes_to_show=11\n",
    "    )\n",
    "    \n",
    "    print(\"\\n DISTILLATION COMPLETED \")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1908726,
     "isSourceIdPinned": false,
     "sourceId": 3132677,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8989699,
     "sourceId": 14112485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9150886,
     "sourceId": 14711312,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9399227,
     "sourceId": 14711423,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9423460,
     "sourceId": 14744741,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38133.699559,
   "end_time": "2026-02-15T19:50:46.916342",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-15T09:15:13.216783",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d80b1e677bd4a7bb403bda4a849f21d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b1b5d4c4ed7f44479a776e5cdbaeaf47",
        "IPY_MODEL_c3482c8642df4536b89e2119ece0ad0f",
        "IPY_MODEL_38e59a4c8eb2400f9a71b2ada4ed2507"
       ],
       "layout": "IPY_MODEL_37e0420f0a534bf4b912714b658708f9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2e33ed969f8a4537ba29a36a4bff8300": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "37e0420f0a534bf4b912714b658708f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38e59a4c8eb2400f9a71b2ada4ed2507": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bac54b9ee5454846a404ac291030131d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f514f683d8a14bc68068e84e5e46def5",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡22.1M/22.1Mâ€‡[00:00&lt;00:00,â€‡28.1MB/s]"
      }
     },
     "5a7caaf15448447a86b9ffe45a23fc6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b1b5d4c4ed7f44479a776e5cdbaeaf47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e1940e95e7ec462bab081c5221222650",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2e33ed969f8a4537ba29a36a4bff8300",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     },
     "bac54b9ee5454846a404ac291030131d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3482c8642df4536b89e2119ece0ad0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eb8d135685a44c93ad5739dc8f3d3ecb",
       "max": 22058004,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5a7caaf15448447a86b9ffe45a23fc6d",
       "tabbable": null,
       "tooltip": null,
       "value": 22058004
      }
     },
     "e1940e95e7ec462bab081c5221222650": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb8d135685a44c93ad5739dc8f3d3ecb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f514f683d8a14bc68068e84e5e46def5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
