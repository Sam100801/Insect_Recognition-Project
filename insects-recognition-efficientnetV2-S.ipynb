{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed911c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-10T17:27:30.622251Z",
     "iopub.status.busy": "2025-12-10T17:27:30.622003Z",
     "iopub.status.idle": "2025-12-10T17:29:05.558558Z",
     "shell.execute_reply": "2025-12-10T17:29:05.557441Z"
    },
    "papermill": {
     "duration": 94.943912,
     "end_time": "2025-12-10T17:29:05.560010",
     "exception": false,
     "start_time": "2025-12-10T17:27:30.616098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libreria di sistema\n",
    "import kagglehub\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "# Installa dipendenze base\n",
    "!pip install torch torchvision\n",
    "!pip install pandas numpy matplotlib seaborn\n",
    "!pip install scikit-learn pillow tqdm\n",
    "!pip install jupyter notebook\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa1455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:05.607710Z",
     "iopub.status.busy": "2025-12-10T17:29:05.607430Z",
     "iopub.status.idle": "2025-12-10T17:29:05.824496Z",
     "shell.execute_reply": "2025-12-10T17:29:05.823701Z"
    },
    "papermill": {
     "duration": 0.242373,
     "end_time": "2025-12-10T17:29:05.825706",
     "exception": false,
     "start_time": "2025-12-10T17:29:05.583333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"rtlmhjbn/ip02-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "186cbbc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:05.870853Z",
     "iopub.status.busy": "2025-12-10T17:29:05.870665Z",
     "iopub.status.idle": "2025-12-10T17:29:09.619828Z",
     "shell.execute_reply": "2025-12-10T17:29:09.619237Z"
    },
    "papermill": {
     "duration": 3.772908,
     "end_time": "2025-12-10T17:29:09.621174",
     "exception": false,
     "start_time": "2025-12-10T17:29:05.848266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Configurazione visualizzazioni\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd1801",
   "metadata": {},
   "source": [
    "# Analisi Distribuzioni Classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31756863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:09.667710Z",
     "iopub.status.busy": "2025-12-10T17:29:09.667396Z",
     "iopub.status.idle": "2025-12-10T17:29:13.337407Z",
     "shell.execute_reply": "2025-12-10T17:29:13.336393Z"
    },
    "papermill": {
     "duration": 3.694685,
     "end_time": "2025-12-10T17:29:13.338710",
     "exception": false,
     "start_time": "2025-12-10T17:29:09.644025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('/kaggle/input/ip02-dataset/classification')\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "VAL_DIR = DATA_DIR / 'val'\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "\n",
    "print(f\"Train directory exists: {TRAIN_DIR.exists()}\")\n",
    "print(f\"Val directory exists: {VAL_DIR.exists()}\")\n",
    "print(f\"Test directory exists: {TEST_DIR.exists()}\")\n",
    "\n",
    "def count_images_per_class(data_dir):\n",
    "    class_counts = {}\n",
    "    \n",
    "    for class_folder in sorted(data_dir.iterdir()):\n",
    "        if class_folder.is_dir():\n",
    "            class_name = class_folder.name\n",
    "            num_images = len(list(class_folder.glob('*.jpg'))) + \\\n",
    "                        len(list(class_folder.glob('*.png'))) + \\\n",
    "                        len(list(class_folder.glob('*.jpeg')))\n",
    "            class_counts[class_name] = num_images\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Conta immagini per split\n",
    "train_counts = count_images_per_class(TRAIN_DIR)\n",
    "val_counts = count_images_per_class(VAL_DIR) if VAL_DIR.exists() else {}\n",
    "test_counts = count_images_per_class(TEST_DIR) if TEST_DIR.exists() else {}\n",
    "\n",
    "# Crea DataFrame\n",
    "df_train = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Train_Count'])\n",
    "if val_counts:\n",
    "    df_val = pd.DataFrame(list(val_counts.items()), columns=['Class', 'Val_Count'])\n",
    "    df_train = df_train.merge(df_val, on='Class', how='outer')\n",
    "if test_counts:\n",
    "    df_test = pd.DataFrame(list(test_counts.items()), columns=['Class', 'Test_Count'])\n",
    "    df_train = df_train.merge(df_test, on='Class', how='outer')\n",
    "\n",
    "df_train = df_train.fillna(0).astype({'Train_Count': int})\n",
    "\n",
    "print(\"STATISTICHE DATASET\")\n",
    "print(f\"Numero totale di classi: {len(train_counts)}\")\n",
    "print(f\"Totale immagini train: {sum(train_counts.values())}\")\n",
    "if val_counts:\n",
    "    print(f\"Totale immagini val: {sum(val_counts.values())}\")\n",
    "if test_counts:\n",
    "    print(f\"Totale immagini test: {sum(test_counts.values())}\")\n",
    "\n",
    "\n",
    "print(\"STATISTICHE TRAIN SET\")\n",
    "print(f\"Media immagini per classe: {np.mean(list(train_counts.values())):.1f}\")\n",
    "print(f\"Mediana: {np.median(list(train_counts.values())):.1f}\")\n",
    "print(f\"Min immagini: {min(train_counts.values())} (classe: {min(train_counts, key=train_counts.get)})\")\n",
    "print(f\"Max immagini: {max(train_counts.values())} (classe: {max(train_counts, key=train_counts.get)})\")\n",
    "print(f\"Std deviation: {np.std(list(train_counts.values())):.1f}\")\n",
    "\n",
    "# Calcola imbalance ratio\n",
    "imbalance_ratio = max(train_counts.values()) / min(train_counts.values())\n",
    "print(f\"\\n IMBALANCE RATIO: {imbalance_ratio:.2f}x\")\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"SEVERAMENTE SBILANCIATO - Necessarie tecniche di bilanciamento!\")\n",
    "elif imbalance_ratio > 5:\n",
    "    print(\"MODERATAMENTE SBILANCIATO - Consigliato class weighting\")\n",
    "else:\n",
    "    print(\"RELATIVAMENTE BILANCIATO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458578d2",
   "metadata": {},
   "source": [
    "# Visualizzazione Distribuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948b891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:13.385991Z",
     "iopub.status.busy": "2025-12-10T17:29:13.385784Z",
     "iopub.status.idle": "2025-12-10T17:29:14.049069Z",
     "shell.execute_reply": "2025-12-10T17:29:14.048387Z"
    },
    "papermill": {
     "duration": 0.689421,
     "end_time": "2025-12-10T17:29:14.051233",
     "exception": false,
     "start_time": "2025-12-10T17:29:13.361812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Distribuzione ordinata\n",
    "sorted_counts = dict(sorted(train_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "axes[0].bar(range(len(sorted_counts)), list(sorted_counts.values()), color='steelblue', alpha=0.7)\n",
    "axes[0].axhline(np.mean(list(train_counts.values())), color='red', linestyle='--', \n",
    "                label=f'Media: {np.mean(list(train_counts.values())):.0f}', linewidth=2)\n",
    "axes[0].set_xlabel('Classe (ordinata per frequenza)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Numero di Immagini', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribuzione Classi - Train Set (Ordinato)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Istogramma distribuzione\n",
    "axes[1].hist(list(train_counts.values()), bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(np.mean(list(train_counts.values())), color='red', linestyle='--', \n",
    "                label=f'Media: {np.mean(list(train_counts.values())):.0f}', linewidth=2)\n",
    "axes[1].axvline(np.median(list(train_counts.values())), color='green', linestyle='--', \n",
    "                label=f'Mediana: {np.median(list(train_counts.values())):.0f}', linewidth=2)\n",
    "axes[1].set_xlabel('Numero di Immagini per Classe', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Frequenza (numero di classi)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Distribuzione della Frequenza delle Classi', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identifica classi problematiche\n",
    "threshold_low = np.percentile(list(train_counts.values()), 25)\n",
    "threshold_high = np.percentile(list(train_counts.values()), 75)\n",
    "\n",
    "underrepresented = {k: v for k, v in train_counts.items() if v < threshold_low}\n",
    "overrepresented = {k: v for k, v in train_counts.items() if v > threshold_high}\n",
    "\n",
    "print(f\"\\nðŸ“Š Classi sotto-rappresentate (<25Â° percentile = {threshold_low:.0f} img): {len(underrepresented)}\")\n",
    "print(f\"ðŸ“Š Classi sovra-rappresentate (>75Â° percentile = {threshold_high:.0f} img): {len(overrepresented)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f68b6f",
   "metadata": {},
   "source": [
    "# Visualizzazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02311287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:22.051214Z",
     "iopub.status.busy": "2025-12-10T17:29:22.050786Z",
     "iopub.status.idle": "2025-12-10T17:29:24.687689Z",
     "shell.execute_reply": "2025-12-10T17:29:24.685417Z"
    },
    "papermill": {
     "duration": 2.725636,
     "end_time": "2025-12-10T17:29:24.750664",
     "exception": false,
     "start_time": "2025-12-10T17:29:22.025028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_sample_images(data_dir, n_classes=6, n_images_per_class=5):\n",
    "    # Mostra immagini di esempio da diverse classi\n",
    "\n",
    "    classes = sorted([d.name for d in data_dir.iterdir() if d.is_dir()])\n",
    "    selected_classes = np.random.choice(classes, min(n_classes, len(classes)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_classes, n_images_per_class, \n",
    "                             figsize=(3*n_images_per_class, 3*n_classes))\n",
    "    fig.suptitle('Esempi di Immagini dal Dataset', fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    for i, class_name in enumerate(selected_classes):\n",
    "        class_dir = data_dir / class_name\n",
    "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
    "        selected_images = np.random.choice(images, min(n_images_per_class, len(images)), replace=False)\n",
    "        \n",
    "        for j, img_path in enumerate(selected_images):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis('off')\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(f'{class_name}\\n({train_counts[class_name]} img)', \n",
    "                                     fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(TRAIN_DIR, n_classes=6, n_images_per_class=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd3629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:24.941050Z",
     "iopub.status.busy": "2025-12-10T17:29:24.940706Z",
     "iopub.status.idle": "2025-12-10T17:29:24.952435Z",
     "shell.execute_reply": "2025-12-10T17:29:24.951392Z"
    },
    "papermill": {
     "duration": 0.108217,
     "end_time": "2025-12-10T17:29:24.954415",
     "exception": false,
     "start_time": "2025-12-10T17:29:24.846198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_class_weights(class_counts):\n",
    "    # Calcola pesi per bilanciare le classi\n",
    "    total = sum(class_counts.values())\n",
    "    n_classes = len(class_counts)\n",
    "    \n",
    "    # Formula: weight = total / (n_classes * class_count)\n",
    "    weights = {cls: total / (n_classes * count) for cls, count in class_counts.items()}\n",
    "    \n",
    "    return weights\n",
    "\n",
    "class_weights = calculate_class_weights(train_counts)\n",
    "\n",
    "# Visualizza top-10 pesi\n",
    "sorted_weights = dict(sorted(class_weights.items(), key=lambda x: x[1], reverse=True)[:50])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 CLASS WEIGHTS (per loss function)\")\n",
    "print(\"=\"*80)\n",
    "for cls, weight in sorted_weights.items():\n",
    "    print(f\"{cls:30s}: {weight:.4f} (n_images={train_counts[cls]})\")\n",
    "\n",
    "# Salva per uso futuro\n",
    "weights_dict = {\n",
    "    'class_weights': class_weights,\n",
    "    'class_counts': train_counts\n",
    "}\n",
    "\n",
    "print(\" EDA COMPLETATA - Prossimo step: implementare data loader e baseline model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0635169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:25.172159Z",
     "iopub.status.busy": "2025-12-10T17:29:25.171347Z",
     "iopub.status.idle": "2025-12-10T17:29:32.857728Z",
     "shell.execute_reply": "2025-12-10T17:29:32.856876Z"
    },
    "papermill": {
     "duration": 7.794021,
     "end_time": "2025-12-10T17:29:32.858856",
     "exception": false,
     "start_time": "2025-12-10T17:29:25.064835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad62b42",
   "metadata": {},
   "source": [
    "# Preparazione Dataset e Bilanciamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efc972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:33.055741Z",
     "iopub.status.busy": "2025-12-10T17:29:33.055443Z",
     "iopub.status.idle": "2025-12-10T17:29:45.356840Z",
     "shell.execute_reply": "2025-12-10T17:29:45.356035Z"
    },
    "papermill": {
     "duration": 12.399402,
     "end_time": "2025-12-10T17:29:45.358261",
     "exception": false,
     "start_time": "2025-12-10T17:29:32.958859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Optional, Dict, Tuple\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "class IP102Dataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        transform=None,\n",
    "        resize_limit=1024,\n",
    "        augment: bool = True,\n",
    "        cache_images: bool = False\n",
    "    ):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.cache_images = cache_images\n",
    "        self.resize_limit = resize_limit\n",
    "        \n",
    "        # Carica immagini e labels\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "        self._load_dataset()\n",
    "        \n",
    "        self.image_cache = {} if cache_images else None\n",
    "        \n",
    "        print(f\"Dataset caricato: {len(self.samples)} immagini, {len(self.class_to_idx)} classi\")\n",
    "    \n",
    "    def _load_dataset(self):\n",
    "        \n",
    "        classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "        self.idx_to_class = {idx: cls_name for cls_name, idx in self.class_to_idx.items()}\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_dir = self.root_dir / class_name\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Trova tutte le immagini\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                for img_path in class_dir.glob(ext):\n",
    "                    self.samples.append((str(img_path), class_idx))\n",
    "    \n",
    "    def get_class_distribution(self) -> Dict[int, int]:\n",
    "        # Restituisce distribuzione delle classi\n",
    "        class_counts = {}\n",
    "        for _, label in self.samples:\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "        return class_counts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _fast_load(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # in caso di errore di lettura\n",
    "        if img is None:\n",
    "            return np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # immagini IP102 molto grandi â†’ riduzione preventiva\n",
    "        h, w = img.shape[:2]\n",
    "        max_dim = max(h, w)\n",
    "        if max_dim > self.resize_limit:\n",
    "            scale = self.resize_limit / max_dim\n",
    "            img = cv2.resize(img, (int(w * scale), int(h * scale)))\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = self._fast_load(img_path)\n",
    "        \n",
    "        # Applica trasformazioni\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "def get_train_transforms(img_size: int = 224):\n",
    "\n",
    "    return A.Compose([\n",
    "\n",
    "        A.RandomResizedCrop(size=(img_size, img_size),scale=(0.7, 1.0),ratio=(0.75, 1.33),p=1.0),\n",
    "        \n",
    "        # Augmentazioni leggere e realistiche\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.25),\n",
    "\n",
    "        A.Rotate(limit=25, p=0.5),\n",
    "        \n",
    "        A.ColorJitter(\n",
    "            brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05,\n",
    "            p=0.5\n",
    "        ),\n",
    "\n",
    "        # leggerissimo rumore\n",
    "        A.GaussNoise(var_limit=(5.0, 15.0), p=0.15),\n",
    "\n",
    "        # piccolo CutOut\n",
    "        A.CoarseDropout(\n",
    "            max_holes=6,\n",
    "            max_height=20,\n",
    "            max_width=20,\n",
    "            min_holes=1,\n",
    "            fill_value=0,\n",
    "            p=0.2\n",
    "        ),\n",
    "\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def get_val_transforms(img_size=224):\n",
    "    \n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_weighted_sampler(dataset: IP102Dataset) -> WeightedRandomSampler:\n",
    "\n",
    "    class_counts = dataset.get_class_distribution()\n",
    "    \n",
    "    # Calcola pesi: inversamente proporzionale alla frequenza\n",
    "    total_samples = len(dataset)\n",
    "    num_classes = len(class_counts)\n",
    "    class_weights = {\n",
    "        cls: total_samples / (num_classes * count) \n",
    "        for cls, count in class_counts.items()\n",
    "    }\n",
    "    \n",
    "    # Assegna peso a ogni sample\n",
    "    sample_weights = [class_weights[label] for _, label in dataset.samples]\n",
    "    \n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    return sampler\n",
    "\n",
    "\n",
    "def get_dataloaders(\n",
    "    train_dir: str,\n",
    "    val_dir: str,\n",
    "    batch_size: int = 32,\n",
    "    img_size: int = 224,\n",
    "    num_workers: int = 4,\n",
    "):\n",
    "    \n",
    "    # Crea transforms\n",
    "    train_transform = get_train_transforms(img_size)\n",
    "    val_transform = get_val_transforms(img_size)\n",
    "    \n",
    "    # Crea datasets\n",
    "    train_dataset = IP102Dataset(train_dir, transform=train_transform)\n",
    "    val_dataset = IP102Dataset(val_dir, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\" Train samples: {len(train_dataset)}\")\n",
    "    print(f\" Val samples:   {len(val_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad038ee",
   "metadata": {},
   "source": [
    "# Visualizzazione immagini dal nuovo DataLoader IP102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c170a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:45.559242Z",
     "iopub.status.busy": "2025-12-10T17:29:45.558470Z",
     "iopub.status.idle": "2025-12-10T17:29:48.936912Z",
     "shell.execute_reply": "2025-12-10T17:29:48.935862Z"
    },
    "papermill": {
     "duration": 3.509939,
     "end_time": "2025-12-10T17:29:48.967870",
     "exception": false,
     "start_time": "2025-12-10T17:29:45.457931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    img = img_tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    img = img * std + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "TRAIN_DIR = \"/kaggle/input/ip02-dataset/classification/train\"\n",
    "VAL_DIR   = \"/kaggle/input/ip02-dataset/classification/val\"\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    val_dir=VAL_DIR,\n",
    "    batch_size=16,\n",
    "    img_size=224,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n Carico un batch dal DataLoaderâ€¦\\n\")\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(\" Batch images:\", images.shape)\n",
    "print(\" Batch labels:\", labels.shape)\n",
    "print(\" Example labels:\", labels[:10].tolist())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.suptitle(\"Esempi di immagini augmentate (train_loader)\", fontsize=16, y=1.02)\n",
    "\n",
    "for i in range(12):  # mostra 12 immagini\n",
    "    img = denormalize(images[i])\n",
    "\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Class {labels[i].item()}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04b7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:49.233728Z",
     "iopub.status.busy": "2025-12-10T17:29:49.232999Z",
     "iopub.status.idle": "2025-12-10T17:29:52.477239Z",
     "shell.execute_reply": "2025-12-10T17:29:52.476258Z"
    },
    "papermill": {
     "duration": 3.377416,
     "end_time": "2025-12-10T17:29:52.478657",
     "exception": false,
     "start_time": "2025-12-10T17:29:49.101241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f02f55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:52.748742Z",
     "iopub.status.busy": "2025-12-10T17:29:52.748437Z",
     "iopub.status.idle": "2025-12-10T17:29:52.754897Z",
     "shell.execute_reply": "2025-12-10T17:29:52.754245Z"
    },
    "papermill": {
     "duration": 0.142532,
     "end_time": "2025-12-10T17:29:52.755911",
     "exception": false,
     "start_time": "2025-12-10T17:29:52.613379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_checkpoints = Path(\"/kaggle/working/checkpoints/Efm\")\n",
    "path_logs = Path(\"/kaggle/working/logs/Efm\")\n",
    "\n",
    "path_checkpoints.mkdir(parents=True, exist_ok=True)\n",
    "path_logs.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if path_checkpoints.exists() and path_checkpoints.is_dir() and path_logs.exists() and path_logs.is_dir():\n",
    "    print(\"Cartelle trovate\")\n",
    "else:\n",
    "    print(\"Cartelle non trovate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c26484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:53.030869Z",
     "iopub.status.busy": "2025-12-10T17:29:53.030585Z",
     "iopub.status.idle": "2025-12-10T17:29:53.036531Z",
     "shell.execute_reply": "2025-12-10T17:29:53.035749Z"
    },
    "papermill": {
     "duration": 0.146281,
     "end_time": "2025-12-10T17:29:53.037702",
     "exception": false,
     "start_time": "2025-12-10T17:29:52.891421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_checkpoints_baseline = Path(\"/kaggle/working/checkpoints/baseline\")\n",
    "path_logs_baseline = Path(\"/kaggle/working/logs/baseline\")\n",
    "\n",
    "path_checkpoints_baseline.mkdir(parents=True, exist_ok=True)\n",
    "path_logs_baseline.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if path_checkpoints_baseline.exists() and path_checkpoints_baseline.is_dir() and path_logs_baseline.exists() and path_logs_baseline.is_dir():\n",
    "    print(\"Cartelle trovate\")\n",
    "else:\n",
    "    print(\"Cartelle non trovate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e4a06",
   "metadata": {},
   "source": [
    "# Esplorazione Modelli EfficientNet (timm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f24c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:53.311059Z",
     "iopub.status.busy": "2025-12-10T17:29:53.310769Z",
     "iopub.status.idle": "2025-12-10T17:29:57.022308Z",
     "shell.execute_reply": "2025-12-10T17:29:57.020894Z"
    },
    "papermill": {
     "duration": 3.850001,
     "end_time": "2025-12-10T17:29:57.023602",
     "exception": false,
     "start_time": "2025-12-10T17:29:53.173601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "# Lista tutti i modelli EfficientNet disponibili\n",
    "efficientnet_models = timm.list_models('*efficientnet*', pretrained=True)\n",
    "print(\"EfficientNet models con pretrained weights:\")\n",
    "for model in efficientnet_models[:50]:  # Mostra primi 50\n",
    "    print(f\"  - {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd33bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:29:57.296072Z",
     "iopub.status.busy": "2025-12-10T17:29:57.295787Z",
     "iopub.status.idle": "2025-12-10T17:30:00.785556Z",
     "shell.execute_reply": "2025-12-10T17:30:00.784731Z"
    },
    "papermill": {
     "duration": 3.626425,
     "end_time": "2025-12-10T17:30:00.786696",
     "exception": false,
     "start_time": "2025-12-10T17:29:57.160271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "m = timm.create_model('efficientnetv2_rw_m.agc_in1k', pretrained=True)\n",
    "print(m.default_cfg['input_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57004765",
   "metadata": {},
   "source": [
    "# Training Pipeline e Ottimizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb68105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T17:30:01.057862Z",
     "iopub.status.busy": "2025-12-10T17:30:01.057588Z",
     "iopub.status.idle": "2025-12-10T23:12:57.346668Z",
     "shell.execute_reply": "2025-12-10T23:12:57.345641Z"
    },
    "papermill": {
     "duration": 20576.433758,
     "end_time": "2025-12-10T23:12:57.353505",
     "exception": false,
     "start_time": "2025-12-10T17:30:00.919747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, \n",
    "    f1_score, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "def mixup_data(x: torch.Tensor, y: torch.LongTensor, alpha: float = 0.3):\n",
    "\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def cutmix_data(x: torch.Tensor, y: torch.LongTensor, alpha: float = 0.5):\n",
    "\n",
    "    \n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size, _, W, H = x.size()\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1.0 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "    \n",
    "    y_a, y_b = y, y[index]\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.9999):\n",
    "        self.decay = decay\n",
    "        self.model = model\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            new_avg = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n",
    "            self.shadow[name] = new_avg.clone()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply_shadow(self):\n",
    "        self.backup = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name].clone()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name].clone()\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "def linear_combination(x, y, epsilon):\n",
    "    return epsilon * x + (1 - epsilon) * y\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction == 'mean' else loss.sum() if reduction == 'sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon: float = 0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, preds, target):\n",
    "        n = preds.size()[-1]\n",
    "        log_preds = F.log_softmax(preds, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return linear_combination(loss / n, nll, self.epsilon)\n",
    "\n",
    "\n",
    "\n",
    "class IP102Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'efficientnetv2_rw_s.ra2_in1k',\n",
    "        num_classes: int = 102,\n",
    "        pretrained: bool = True,\n",
    "        dropout: float = 0.2, \n",
    "        drop_path_rate: float = 0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Carica backbone con stochastic depth\n",
    "        try:\n",
    "            self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool='avg',\n",
    "            drop_path_rate=drop_path_rate\n",
    "            )\n",
    "        except:\n",
    "            print(\" drop_path_rate non supportato\")\n",
    "            self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "            )\n",
    "        \n",
    "        # get number of features\n",
    "        num_features = getattr(self.backbone, 'num_features', None)\n",
    "\n",
    "        if num_features is None:\n",
    "            with torch.no_grad():\n",
    "                dummy = torch.randn(1, 3, 384, 384)\n",
    "                out = self.backbone(dummy)\n",
    "                num_features = out.shape[1]\n",
    "        \n",
    "        # Classifier piÃ¹ robusto con BatchNorm\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        print(f\" Modello: {model_name}\")\n",
    "        print(f\" Features: {num_features}, Dropout: {dropout}, Drop Path: {drop_path_rate}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        # Congela backbone per fine-tuning graduale\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\" Backbone congelato\")\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "        # Scongela backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\" Backbone scongelato\")\n",
    "\n",
    "class Trainer:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        accum_steps=1,\n",
    "        device: str = 'cuda',\n",
    "        save_dir: str = './checkpoints',\n",
    "        log_dir: str = './logs',\n",
    "        use_mixup: bool = False,\n",
    "        use_cutmix: bool = True,\n",
    "        use_amp: bool = True,\n",
    "        use_ema: bool = True,\n",
    "        ema_decay: float = 0.999,\n",
    "        mixup_prob: float = 0.5,\n",
    "        mixup_alpha: float = 0.4,\n",
    "        cutmix_alpha: float = 1.0,\n",
    "        grad_clip: float = 5.0\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.accum_steps = accum_steps\n",
    "        self.device = device\n",
    "        \n",
    "        self.use_mixup = use_mixup\n",
    "        self.use_cutmix = use_cutmix\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.cutmix_alpha = cutmix_alpha\n",
    "        self.grad_clip = grad_clip\n",
    "\n",
    "        self.use_amp = use_amp\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "        self.use_ema = use_ema\n",
    "        self.ema = EMA(self.model, decay=ema_decay) if self.use_ema else None\n",
    "        \n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': [],\n",
    "            'val_balanced_acc': [], 'val_f1': [],\n",
    "            'test_loss': None, 'test_acc': None,\n",
    "            'test_balanced_acc': None, 'test_f1': None,\n",
    "            'lr': [], \n",
    "        }\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_balanced_acc = 0.0\n",
    "        self._patience_counter = 0\n",
    "\n",
    "\n",
    "    def tta_forward(self, images):\n",
    "\n",
    "        flips = [\n",
    "            images,\n",
    "            torch.flip(images, dims=[3])\n",
    "        ]\n",
    "\n",
    "        logits_sum = 0\n",
    "\n",
    "        for f in flips:\n",
    "            with autocast(enabled=True):\n",
    "                out = self.model(f.float())\n",
    "            logits_sum += out    \n",
    "\n",
    "        return logits_sum / len(flips)\n",
    "\n",
    "    \n",
    "    \n",
    "    def train_epoch(self, epoch: int) -> Tuple[float, Optional[float]]:\n",
    "   \n",
    "        self.model.train()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        clean_running_loss = 0.0\n",
    "        clean_samples = 0\n",
    "\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch} [TRAIN]')\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            will_mix = (random.random() < self.mixup_prob) and (self.use_mixup or self.use_cutmix)\n",
    "            \n",
    "            if will_mix:\n",
    "                if self.use_mixup and self.use_cutmix:\n",
    "                    if random.random() < 0.5:\n",
    "                        images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=self.mixup_alpha)\n",
    "                    else:\n",
    "                        images, labels_a, labels_b, lam = cutmix_data(images, labels, alpha=self.cutmix_alpha)\n",
    "                elif self.use_mixup:\n",
    "                    images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=self.mixup_alpha)\n",
    "                else:\n",
    "                    images, labels_a, labels_b, lam = cutmix_data(images, labels, alpha=self.cutmix_alpha)\n",
    "\n",
    "            if (batch_idx % self.accum_steps) == 0:\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with autocast(enabled=self.use_amp):\n",
    "                outputs = self.model(images)\n",
    "                if will_mix:\n",
    "                    loss = mixup_criterion(self.criterion, outputs, labels_a, labels_b, lam)\n",
    "                else:\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "\n",
    "                    clean_running_loss += loss.item() * images.size(0)\n",
    "                    clean_samples += images.size(0)\n",
    "\n",
    "            loss = loss / self.accum_steps\n",
    "\n",
    "            if self.use_amp:\n",
    "                # backward AMP\n",
    "                self.scaler.scale(loss).backward()\n",
    "\n",
    "                # grad clipping va fatto dopo unscale\n",
    "                if self.grad_clip and self.grad_clip > 0.:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n",
    "\n",
    "                if (batch_idx % self.accum_steps) == (self.accum_steps - 1):\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "\n",
    "            else:\n",
    "                loss.backward()\n",
    "                \n",
    "                if self.grad_clip and self.grad_clip > 0.:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n",
    "                    \n",
    "                if (batch_idx % self.accum_steps) == (self.accum_steps - 1):    \n",
    "                    self.optimizer.step()\n",
    "\n",
    "            if self.use_ema:\n",
    "                self.ema.update()\n",
    "\n",
    "            running_loss += (loss.item() * self.accum_steps) * images.size(0)\n",
    "\n",
    "            if not will_mix:\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "        clean_loss = clean_running_loss / clean_samples if clean_samples > 0 else None\n",
    "        epoch_acc = correct / total if total > 0 else None\n",
    "\n",
    "        return epoch_loss, epoch_acc, clean_loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch: int) -> Dict[str, object]:\n",
    "\n",
    "        if self.use_ema and self.ema is not None:\n",
    "            self.ema.apply_shadow()\n",
    "        \n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        pbar = tqdm(self.val_loader, desc=f'Epoch {epoch} [VAL]')\n",
    "\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device,non_blocking=True)\n",
    "            \n",
    "            try:\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\" Batch saltato per errore: {e}\")\n",
    "                continue\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        # ripristina pesi dopo la validazione\n",
    "        if self.use_ema and self.ema is not None:\n",
    "            self.ema.restore()\n",
    "        \n",
    "        val_loss = running_loss / len(self.val_loader.dataset)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        val_balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        val_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "        val_f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        return {\n",
    "            'loss': val_loss,\n",
    "            'accuracy': val_acc,\n",
    "            'balanced_accuracy': val_balanced_acc,\n",
    "            'f1_macro': val_f1_macro,\n",
    "            'f1_weighted': val_f1_weighted,\n",
    "            'preds': all_preds,\n",
    "            'labels': all_labels\n",
    "        }\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, test_loader, use_tta=True):\n",
    "        print(\" TEST SET EVALUATION\")\n",
    "\n",
    "        # Usa EMA per il test\n",
    "        if self.use_ema and self.ema is not None:\n",
    "            self.ema.apply_shadow()\n",
    "\n",
    "        self.model.eval()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in tqdm(test_loader, desc='[TEST]'):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "            if use_tta:\n",
    "                with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                    outputs = self.tta_forward(images)\n",
    "            else:\n",
    "                with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "                    outputs = self.model(images)\n",
    "\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        test_loss = running_loss / len(test_loader.dataset)\n",
    "        test_acc = accuracy_score(all_labels, all_preds)\n",
    "        test_balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "        print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "        print(f\"Test Acc:  {test_acc:.4f}\")\n",
    "        print(f\"Balanced:  {test_balanced_acc:.4f}\")\n",
    "        print(f\"F1 macro:  {test_f1_macro:.4f}\")\n",
    "\n",
    "        # Confusion matrix test\n",
    "        self.plot_confusion_matrix(all_labels, all_preds, epoch=\"TEST\")\n",
    "\n",
    "        self.history['test_loss'] = test_loss\n",
    "        self.history['test_acc'] = test_acc\n",
    "        self.history['test_balanced_acc'] = test_balanced_acc\n",
    "        self.history['test_f1'] = test_f1_macro\n",
    "        self.save_history()\n",
    "\n",
    "        return {\n",
    "            'loss': test_loss,\n",
    "            'accuracy': test_acc,\n",
    "            'balanced_accuracy': test_balanced_acc,\n",
    "            'f1_macro': test_f1_macro,\n",
    "            'preds': all_preds,\n",
    "            'labels': all_labels\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        num_epochs: int = 50,\n",
    "        early_stopping_patience: int = 15,\n",
    "        freeze_epochs: int = 5,\n",
    "        save_best_only: bool = False\n",
    "    ):\n",
    "        print(f\"Epochs: {num_epochs}, Early Stop Patience: {early_stopping_patience}\")\n",
    "        print(f\"Freeze Backbone: {freeze_epochs} epochs\")\n",
    "        print(f\"Mixup: {self.use_mixup}, CutMix: {self.use_cutmix}, mix_prob: {self.mixup_prob}\")\n",
    "        print(f\"Gradient Clipping: {self.grad_clip}\")\n",
    "\n",
    "\n",
    "        # Freeze backbone initially\n",
    "        if freeze_epochs > 0:\n",
    "                self.model.freeze_backbone()\n",
    "\n",
    "\n",
    "        patience_counter = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            \n",
    "            if freeze_epochs > 0 and epoch == freeze_epochs + 1:\n",
    "\n",
    "                if hasattr(self.model, 'unfreeze_backbone'):\n",
    "                    self.model.unfreeze_backbone()\n",
    "                else:\n",
    "                    for p in self.model.parameters():\n",
    "                        p.requires_grad = True\n",
    "\n",
    "                backbone_params = []\n",
    "                head_params = []\n",
    "                \n",
    "                for name, p in self.model.named_parameters():\n",
    "                    if \"classifier\" in name:\n",
    "                        head_params.append(p)\n",
    "                    else:\n",
    "                        backbone_params.append(p)\n",
    "\n",
    "                self.optimizer = optim.AdamW(\n",
    "                    [\n",
    "                        {\"params\": backbone_params, \"lr\": 1e-5}, \n",
    "                        {\"params\": head_params, \"lr\": 1e-4},     \n",
    "                    ],\n",
    "                    weight_decay=1e-4,\n",
    "                )\n",
    "\n",
    "                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    self.optimizer,\n",
    "                    T_max=num_epochs - epoch,\n",
    "                    eta_min=1e-7                                                            \n",
    "                )\n",
    "                \n",
    "                # reset scaler per sicurezza\n",
    "                self.scaler = GradScaler(enabled=self.use_amp)\n",
    "                print(\" Backbone sbloccato + optimizer/scheduler aggiornati\")\n",
    "                \n",
    "            \n",
    "            train_loss, train_acc, clean_loss = self.train_epoch(epoch)\n",
    "            val_metrics = self.validate(epoch)\n",
    "\n",
    "            # Scheduler step (safe call)\n",
    "            if self.scheduler is not None:\n",
    "                try:\n",
    "                    self.scheduler.step()\n",
    "                except TypeError:\n",
    "                    try:\n",
    "                        self.scheduler.step(epoch)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "          \n",
    "            current_lrs = [param_group['lr'] for param_group in self.optimizer.param_groups]\n",
    "            \n",
    "            self.history['lr'].append(current_lrs)\n",
    "\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history.setdefault('clean_train_loss', []).append(clean_loss)\n",
    "            self.history['val_loss'].append(val_metrics['loss'])\n",
    "\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_acc'].append(val_metrics['accuracy'])\n",
    "\n",
    "            self.history['val_balanced_acc'].append(val_metrics['balanced_accuracy'])\n",
    "            self.history['val_f1'].append(val_metrics['f1_macro']) \n",
    "\n",
    "            # Print metriche\n",
    "            \n",
    "            overfit_gap = train_acc - val_metrics['accuracy']\n",
    "\n",
    "            print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "            if train_acc is not None:\n",
    "                print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "            else:\n",
    "                print(f\"Train Loss: {train_loss:.4f} | Train Acc: n/a (mixing used)\")\n",
    "                \n",
    "            print(f\"Val Loss:   {val_metrics['loss']:.4f} | Val Acc:   {val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Balanced Acc: {val_metrics['balanced_accuracy']:.4f} | F1: {val_metrics['f1_macro']:.4f}\")\n",
    "            print(f\" Overfit Gap: {overfit_gap:.4f} ({overfit_gap*100:.1f}%)\")\n",
    "            print(f\"LR: {current_lrs[0]:.6f}\")\n",
    "            \n",
    "            is_best = val_metrics['balanced_accuracy'] > self.best_balanced_acc\n",
    "            if is_best:\n",
    "                self.best_balanced_acc = val_metrics['balanced_accuracy']\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                print(f\" Best model - Balanced Acc: {self.best_balanced_acc:.4f}\")\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            self._patience_counter = patience_counter\n",
    "            self.save_checkpoint(epoch, is_best=is_best)\n",
    "            \n",
    "            self.save_history()\n",
    "            self.plot_training_curves()\n",
    "            \n",
    "            if is_best:\n",
    "                self.plot_confusion_matrix(val_metrics['labels'], val_metrics['preds'], epoch)\n",
    "            \n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"\\n Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Patience: {patience_counter}/{early_stopping_patience}\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n COMPLETATO in {total_time/60:.2f} min\")\n",
    "        print(f\"Best Val Acc: {self.best_val_acc:.4f}, Balanced: {self.best_balanced_acc:.4f}\\n\")\n",
    "        \n",
    "        # Salvataggio finale\n",
    "        self.save_history()\n",
    "\n",
    "        self.plot_training_curves()\n",
    "    \n",
    "    def save_checkpoint(self, epoch: int, is_best: bool = False):\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scaler_state': self.scaler.state_dict() if self.use_amp else None,\n",
    "            'ema_state': (self.ema.shadow if (self.use_ema and self.ema is not None) else None),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'best_balanced_acc': self.best_balanced_acc,\n",
    "            'history': self.history,\n",
    "            'patience_counter': 0 if is_best else getattr(self, '_patience_counter', 0)\n",
    "        }\n",
    "        \n",
    "        # Salva ultimo checkpoint (per resume)\n",
    "        last_checkpoint_path = self.save_dir / 'last_checkpoint.pth'\n",
    "        torch.save(checkpoint, last_checkpoint_path)\n",
    "        print(f\" Checkpoint salvato: epoch {epoch}\")\n",
    "        \n",
    "        # Salva best model separatamente\n",
    "        if is_best:\n",
    "            best_checkpoint_path = self.save_dir / 'best_model.pth'\n",
    "            torch.save(checkpoint, best_checkpoint_path)\n",
    "            print(f\" Best model aggiornato!\")\n",
    "        \n",
    "        # Salva backup ogni 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            backup_path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'\n",
    "            torch.save(checkpoint, backup_path)\n",
    "            print(f\" Backup salvato: epoch {epoch}\")\n",
    "    \n",
    "    def save_history(self):\n",
    "        with open(self.log_dir / 'history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "    \n",
    "    def plot_confusion_matrix(self, labels, preds, epoch):\n",
    "\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        \n",
    "        num_classes = self.model.classifier[-1].out_features\n",
    "\n",
    "        if num_classes <= 20:\n",
    "            class_list = np.arange(num_classes)\n",
    "            cm = confusion_matrix(labels, preds, labels=class_list)\n",
    "\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "                        xticklabels=class_list, yticklabels=class_list)\n",
    "\n",
    "        else:\n",
    "            unique, counts = np.unique(labels, return_counts=True)\n",
    "            top_classes = unique[np.argsort(counts)[-20:]]\n",
    "\n",
    "            mask = np.isin(labels, top_classes)\n",
    "            cm = confusion_matrix(labels[mask], preds[mask], labels=top_classes)\n",
    "\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "                        xticklabels=top_classes, yticklabels=top_classes)\n",
    "\n",
    "        plt.title(f'Confusion Matrix - Epoch {epoch}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.log_dir / f'confusion_matrix_ep{epoch}.png', dpi=150)\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_training_curves(self):\n",
    "        if len(self.history['train_loss']) == 0:\n",
    "            return\n",
    "        \n",
    "        clean_available = 'clean_train_loss' in self.history and any(\n",
    "        x is not None for x in self.history['clean_train_loss']\n",
    "        )\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        epochs = range(1, len(self.history['train_loss']) + 1)\n",
    "\n",
    "        if clean_available:\n",
    "            axes[0, 0].plot(epochs, self.history['clean_train_loss'], \n",
    "                            label='Clean Train Loss (no mixup)', color='green')\n",
    "        \n",
    "        axes[0, 0].plot(epochs, self.history['val_loss'], label='Val', color=\"red\")\n",
    "        axes[0, 0].set_title('Loss'); axes[0, 0].legend()\n",
    "\n",
    "        # Accuracy\n",
    "        axes[0, 1].plot(epochs, self.history['train_acc'], label='Train')\n",
    "        axes[0, 1].plot(epochs, self.history['val_acc'], label='Val')\n",
    "        axes[0, 1].set_title('Accuracy'); axes[0, 1].legend()\n",
    "\n",
    "        # Overfitting gap\n",
    "        gap = [t - v for t, v in zip(self.history['train_acc'], self.history['val_acc'])]\n",
    "        axes[1, 0].plot(epochs, gap)\n",
    "        axes[1, 0].axhline(y=0, linestyle='--', alpha=0.5)\n",
    "        axes[1, 0].set_title('Overfitting Gap (Train - Val)')\n",
    "\n",
    "        # Metrics\n",
    "        axes[1, 1].plot(epochs, self.history['val_balanced_acc'], label='Balanced Acc Val')\n",
    "        axes[1, 1].plot(epochs, self.history['val_f1'], label='F1 Macro Val')\n",
    "\n",
    "        axes[1, 1].set_title('Validation Metrics'); axes[1, 1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.log_dir / 'training_curves.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "def get_dataloaders(\n",
    "    train_dir: str,\n",
    "    val_dir: str,\n",
    "    test_dir: str,\n",
    "    batch_size: int = 16,\n",
    "    img_size: int = 224,\n",
    "    augment_level: str = 'heavy',\n",
    "    use_weighted_sampling: bool = True,\n",
    "    num_workers: int = 4\n",
    "):\n",
    "    # transforms\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "    if augment_level == 'heavy':\n",
    "        train_tf = T.Compose([\n",
    "            T.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply([T.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=mean, std=std),\n",
    "            T.RandomErasing(p=0.15)\n",
    "        ])\n",
    "    else:\n",
    "        train_tf = T.Compose([\n",
    "            T.Resize(int(img_size*1.15)),\n",
    "            T.CenterCrop(img_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "\n",
    "    val_tf = T.Compose([\n",
    "        T.Resize(int(img_size*1.1)),\n",
    "        T.CenterCrop(img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
    "    val_ds = datasets.ImageFolder(val_dir, transform=val_tf)\n",
    "    test_ds = datasets.ImageFolder(test_dir, transform=val_tf)\n",
    "\n",
    "    \n",
    "    if use_weighted_sampling:\n",
    "        class_counts = np.bincount([y for _, y in train_ds.samples])\n",
    "        weights = 1.0 / (class_counts + 1e-6)\n",
    "        sample_weights = torch.tensor([weights[y] for _, y in train_ds.samples], dtype=torch.float)\n",
    "        \n",
    "        sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_ds, \n",
    "            batch_size=batch_size, \n",
    "            sampler=sampler, \n",
    "            num_workers=num_workers, \n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )    \n",
    "    else:\n",
    "        train_loader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "            )\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_ds\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    CONFIG = {\n",
    "        # Paths\n",
    "        'train_dir': '/kaggle/input/ip02-dataset/classification/train',\n",
    "        'val_dir': '/kaggle/input/ip02-dataset/classification/val',\n",
    "        'test_dir': '/kaggle/input/ip02-dataset/classification/test',\n",
    "        'save_dir': '/kaggle/working/checkpoints',\n",
    "        'log_dir': '/kaggle/working/logs',\n",
    "        \n",
    "        # Model\n",
    "        'model_name': 'efficientnetv2_rw_s.ra2_in1k',\n",
    "        'num_classes': 102,\n",
    "        'pretrained': True,\n",
    "        'dropout': 0.2,  \n",
    "        'drop_path_rate': 0.2, \n",
    "        \n",
    "        # Training\n",
    "        'batch_size': 32, \n",
    "        'img_size': 384,  \n",
    "        'num_epochs': 25,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'augment_level': 'heavy',\n",
    "        'use_weighted_sampling': True,\n",
    "        \n",
    "        # Regularization\n",
    "        'label_smoothing': 0.1,\n",
    "        'use_mixup': True,\n",
    "        'use_cutmix': True,\n",
    "        'mixup_alpha': 0.1,\n",
    "        'cutmix_alpha': 0.5,\n",
    "        'mixup_prob': 0.2,\n",
    "        'grad_clip': 1.0,\n",
    "        'freeze_backbone_epochs': 3,\n",
    "        'early_stopping_patience': 15,\n",
    "        \n",
    "        # Hardware\n",
    "        'num_workers': 4,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    "    \n",
    "    print(\"âš™ï¸  CONFIGURAZIONE\")\n",
    "    for key, value in CONFIG.items():\n",
    "        print(f\"{key:30s}: {value}\")\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader, val_loader, test_loader, train_ds = get_dataloaders(\n",
    "        train_dir=CONFIG['train_dir'],\n",
    "        val_dir=CONFIG['val_dir'],\n",
    "        test_dir=CONFIG['test_dir'],\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        img_size=CONFIG['img_size'],\n",
    "        augment_level=CONFIG['augment_level'],\n",
    "        use_weighted_sampling=CONFIG['use_weighted_sampling'],\n",
    "        num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = IP102Classifier(\n",
    "        model_name=CONFIG['model_name'],\n",
    "        num_classes=CONFIG['num_classes'],\n",
    "        pretrained=CONFIG['pretrained'],\n",
    "        dropout=CONFIG['dropout'],\n",
    "        drop_path_rate=CONFIG['drop_path_rate']\n",
    "    )\n",
    "    \n",
    "\n",
    "    if CONFIG[\"label_smoothing\"] > 0:\n",
    "        criterion = LabelSmoothingCrossEntropy(epsilon=CONFIG[\"label_smoothing\"])\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    base_lr = CONFIG['learning_rate'] if CONFIG['learning_rate'] is not None else 1e-5\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=base_lr,\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "\n",
    "    # scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=CONFIG[\"num_epochs\"] - CONFIG['freeze_backbone_epochs'],\n",
    "    eta_min=1e-7\n",
    "    )\n",
    "\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=CONFIG['device'],\n",
    "        save_dir=CONFIG['save_dir'],\n",
    "        log_dir=CONFIG['log_dir'],\n",
    "        use_mixup=CONFIG['use_mixup'],\n",
    "        use_cutmix=CONFIG['use_cutmix'],\n",
    "        mixup_prob=CONFIG['mixup_prob'],\n",
    "        mixup_alpha=CONFIG['mixup_alpha'],\n",
    "        cutmix_alpha=CONFIG['cutmix_alpha'],\n",
    "        grad_clip=CONFIG['grad_clip'],\n",
    "        use_amp=True,\n",
    "        use_ema=True,\n",
    "        ema_decay=0.999\n",
    "    )\n",
    "    \n",
    "    # Training\n",
    "    trainer.train(\n",
    "        num_epochs=CONFIG['num_epochs'],\n",
    "        early_stopping_patience=CONFIG['early_stopping_patience'],\n",
    "        freeze_epochs=CONFIG['freeze_backbone_epochs']\n",
    "    )\n",
    "\n",
    "    # Test\n",
    "    results = trainer.test(test_loader, use_tta=True)\n",
    "    \n",
    "    print(\"\\n Training completato!\")\n",
    "    print(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1908726,
     "isSourceIdPinned": false,
     "sourceId": 3132677,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20738.818782,
   "end_time": "2025-12-10T23:13:04.625801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-10T17:27:25.807019",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01f657c1929d4ca29c90e0c274daa4df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7d515974dad465fbd3886522aa912d6",
       "max": 96483448,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ece1341f9364451bb8f945cb9af340a1",
       "tabbable": null,
       "tooltip": null,
       "value": 96483448
      }
     },
     "02097ba54c6a4a259841a5a3b7a70ab7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "088a7f2ba6714351915527b5746f03cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bdd7904f66db48558609f6c3918dfd87",
       "max": 214290028,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_02097ba54c6a4a259841a5a3b7a70ab7",
       "tabbable": null,
       "tooltip": null,
       "value": 214290028
      }
     },
     "15032f96d280411d8fdab43d10632c97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e7684f1ce69648a0b62d93246c71331b",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9181a973ee304510a99f887327782699",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡96.5M/96.5Mâ€‡[00:01&lt;00:00,â€‡35.7MB/s]"
      }
     },
     "19f4cc6675424fab9f9b185fc92a888e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "26766120d028492fb0b8d1c043eeb276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3435756a47e449f0afcbb24a5c330182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c9398f77ed8f47f68b865b6a0a7cb75a",
        "IPY_MODEL_01f657c1929d4ca29c90e0c274daa4df",
        "IPY_MODEL_15032f96d280411d8fdab43d10632c97"
       ],
       "layout": "IPY_MODEL_5d47e84a8fc245a88e51cc1a3bc12c8d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4e1beb6eadad4c2e97fd4457ee8c5ac1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59c2d59de155492494da078e7a5590c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d47e84a8fc245a88e51cc1a3bc12c8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f8ad7098ec64653b4d846c46c4d9b96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b503d585e5b149cdb5f3187c16949157",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_26766120d028492fb0b8d1c043eeb276",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡214M/214Mâ€‡[00:02&lt;00:00,â€‡114MB/s]"
      }
     },
     "9181a973ee304510a99f887327782699": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9883daff09f8481b9029c71fe2aa1788": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a139406057ea48c4863b457e65048a54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b503d585e5b149cdb5f3187c16949157": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7d515974dad465fbd3886522aa912d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bdd7904f66db48558609f6c3918dfd87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c9398f77ed8f47f68b865b6a0a7cb75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a139406057ea48c4863b457e65048a54",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_19f4cc6675424fab9f9b185fc92a888e",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     },
     "d730c4b92af84bd2bf101729e62c72e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fe7e90f099c540f580d20d9abea5a1aa",
        "IPY_MODEL_088a7f2ba6714351915527b5746f03cc",
        "IPY_MODEL_7f8ad7098ec64653b4d846c46c4d9b96"
       ],
       "layout": "IPY_MODEL_9883daff09f8481b9029c71fe2aa1788",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e7684f1ce69648a0b62d93246c71331b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ece1341f9364451bb8f945cb9af340a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fe7e90f099c540f580d20d9abea5a1aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4e1beb6eadad4c2e97fd4457ee8c5ac1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_59c2d59de155492494da078e7a5590c8",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
